# ğŸ¯ Cross-App Lifetime Value (LTV) Prediction Using Multimodal Behavioral Data

A production-grade machine learning workflow for predicting **user Lifetime Value (LTV)** across multiple apps using **multimodal behavioral data**.

This project simulates a real AdTech environment where users interact with several apps, generating:
- ğŸ§© **Sequential events** (modeled with Transformers)
- ğŸ“Š **Aggregated tabular features** (engagement, revenue, retention)

The goal is to build a **multimodal ML pipeline** that significantly outperforms tabular-only baselines.

---

## ğŸ“Œ 1. Why This Matters (Problem Overview)

Accurately predicting user LTV is essential for:

- ğŸ“ˆ Acquisition bidding optimization (CPI / CPA)
- ğŸ’¸ ROAS forecasting and budget allocation
- ğŸ” Early identification of high-value segments
- ğŸ” Cross-app engagement modeling
- ğŸ§  Portfolio-wide user understanding

This repository shows how to combine **sequence modeling + tabular modeling** for improved predictive accuracy.

---

## ğŸ§  2. Technical Approach

### **2.1 Data Modalities**
The project uses *two* feature types:

#### ğŸ”¹ Sequential Input  
Time-ordered user events (per app), modeled with **Transformers**:
- session length  
- view count  
- app launch sequence  
- completion ratios  
- engagement streaks  

#### ğŸ”¹ Tabular Input
Aggregated behavioral metrics:
- total revenue  
- average retention  
- total sessions  
- ARPU  
- churn probability proxies  

---

## ğŸ§± 3. Model Architecture

### ğŸ”¸ **Multimodal Fusion Model**
- Transformer encoder â†’ event embeddings  
- Tabular MLP â†’ dense features  
- Concatenation â†’ fusion layer  
- Regression head â†’ predicted LTV  

Includes:
- ğŸ§ª PyTorch Lightning training loop  
- ğŸ§® XGBoost/LinearRegression baselines  
- ğŸ› Automatic validation metrics  

---

## ğŸ”§ 4. Pipeline Steps

1. Generate synthetic multimodal dataset  
2. Prepare event sequences + tabular matrices  
3. Train multimodal Transformer fusion model  
4. Evaluate on hold-out test set  
5. Train and compare baseline tabular model  
6. Print metrics (RÂ², MAE)  

---

## ğŸ§ª 5. Results

From your run:

| Model | RÂ² | MAE | Notes |
|-------|------|-------|--------|
| **Transformer + Tabular** | **0.9860** | **2.40** | âœ” Best performance |
| **Linear Regression (tabular-only)** | 0.9860 | 2.68 | Worse MAE |

ğŸ“Œ **~10% MAE improvement** â†’ sequence modeling adds meaningful predictive power.

---

## ğŸ“ 6. Repository Structure

cross-app-ltv-prediction/
â”‚â”€â”€ data/
â”‚ â”œâ”€â”€ multimodal_events.csv
â”‚ â”œâ”€â”€ tabular_features.csv
â”‚
â”‚â”€â”€ src/
â”‚ â”œâ”€â”€ generate_synthetic_data.py
â”‚ â”œâ”€â”€ dataset.py
â”‚ â”œâ”€â”€ model.py
â”‚ â”œâ”€â”€ train.py
â”‚ â”œâ”€â”€ evaluate.py
â”‚
â”œâ”€â”€ requirements.txt
â”œâ”€â”€ README.md
â””â”€â”€ .gitignore


---

## ğŸ“¦ 7. Requirements

Install dependencies:

```bash
pip install -r requirements.txt
```

---

## ğŸš€ 8. Training

Run full training pipeline:

```
python src/train.py
```

---

## ğŸ§ª 9. Evaluation

```
python src/evaluate.py
```

Outputs include:

RÂ² score

MAE

Baseline vs multimodal comparison

---

Optional model checkpoints

## â­ 10. Key Features

âœ” Synthetic userâ€“action dataset generator

âœ” Transformer-based sequential encoder

âœ” Tabular + sequential fusion

âœ” PyTorch Lightning training

âœ” XGBoost/Linear regression baselines

âœ” Metrics for direct comparison

âœ” Fully reproducible project

---

## ğŸ§© Future Improvements

Add LSTM or CNN sequence encoders

Add GBDT fusion (CatBoost/XGBoost)

Add Databricks/mlflow integration

Cross-validation on temporal splits

---

## ğŸ™‹â€â™‚ï¸ Author

Juan SebastiÃ¡n Enciso GarcÃ­a
Data Scientist | Machine Learning | Reinforcement Learning



